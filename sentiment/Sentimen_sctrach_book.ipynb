{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the reqed libraries for scraping from Twitter and Reddit \n",
    "import tweepy # twitter api module \n",
    "import plotly.express as px \n",
    "import panel as pn\n",
    "pn.extension('plotly')\n",
    "import hvplot.pandas # plotting and visuliaizng the data \n",
    "import praw # reddit api module \n",
    "import os  # os module to access the .env file \n",
    "from dotenv import load_dotenv \n",
    "import torch # required library for transformers models \n",
    "import pandas as pd # data manipulation \n",
    "\n",
    "from bs4 import BeautifulSoup as bs # scraping and html parsing for some sites\n",
    "import requests as rq # required for scraping from finviz.com\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification # NLP \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the env varibles for the twitter and Reddit \n",
    "\n",
    "#load the function to work with env file\n",
    "load_dotenv()\n",
    "\n",
    "#create the twitter api access varibles \n",
    "twit_api= os.getenv(\"TWIT_API\")\n",
    "twit_secret = os.getenv(\"TWIT_SECRET\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "access_token_secret = os.getenv(\"ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "# authentication for the twitter api \n",
    "auth = tweepy.OAuthHandler(twit_api, twit_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "#createing the API object\n",
    "t_api = tweepy.API(auth)\n",
    "\n",
    "#create the reddit api access object and set to read-only \n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_SEC\"),\n",
    "    password=os.getenv(\"REDDIT_PASS\"),\n",
    "    user_agent=\"stock_dashboard by u/CryptoFoDayz\",\n",
    "    username=os.getenv(\"REDDIT_USER\"),\n",
    ")\n",
    "reddit.read_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing the Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'API' object has no attribute 'full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h4/m4qlztkx7ljd8rgkq9h9bwpr0000gn/T/ipykernel_55432/3775796580.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnvd_30\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NVD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnvd_30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'API' object has no attribute 'full'"
     ]
    }
   ],
   "source": [
    "nvd_30 = t_api.full('1month', 'NVD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(nvd_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              User                                              Tweet  \\\n",
      "0          AmakaCd  RT @delltronic2: @Scarcity_Mining @AmakaCd @no...   \n",
      "1        ibrhm0172  RT @hakanrecepogluu: #Bitcoin \\n\\nArkadaÅŸlar e...   \n",
      "2        moon_bore  RT @kundunsan: In one week circulating supply ...   \n",
      "3        TheRwopsa  RT @LATESTDAONEWS: Since we have invested in #...   \n",
      "4          ts808hw  RT @JasonPLowery: At this rate, by the time I ...   \n",
      "..             ...                                                ...   \n",
      "995     OneCTrader                                @BTC_Archive #Space   \n",
      "996     jiraphamiw                                    @BTC_Archive ðŸ˜±ðŸ˜±   \n",
      "997  mack_barnes0x  RT @CarpeNoctom: \"There are certainly a large ...   \n",
      "998       missuufe  RT @EShib_token: +10,000 watchlists in @CoinMa...   \n",
      "999    CaniGarcia2  RT @Numbrs: Over the last year, the number of ...   \n",
      "\n",
      "                         Time  \n",
      "0   2022-02-09 13:56:57+00:00  \n",
      "1   2021-01-28 12:36:44+00:00  \n",
      "2   2021-10-07 17:40:33+00:00  \n",
      "3   2020-09-28 20:10:23+00:00  \n",
      "4   2017-01-05 21:21:08+00:00  \n",
      "..                        ...  \n",
      "995 2021-02-26 07:31:33+00:00  \n",
      "996 2021-08-31 14:09:30+00:00  \n",
      "997 2017-07-03 11:03:30+00:00  \n",
      "998 2021-08-22 10:56:48+00:00  \n",
      "999 2019-09-16 20:38:53+00:00  \n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "User                  object\n",
      "Tweet                 object\n",
      "Time     datetime64[ns, UTC]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# search tweets\n",
    "keywords = 'NVDA'\n",
    "limit=1000\n",
    "\n",
    "tweets = tweepy.Cursor(t_api.search_tweets, q=keywords, count=1000, tweet_mode='extended').items(limit)\n",
    "\n",
    "# create DataFrame\n",
    "columns = ['User', 'Tweet' , 'Time']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.user.screen_name, tweet.full_text , tweet.user.created_at])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "pattern = '(RT @)\\w+:'\n",
    "df['Tweet'] =df['Tweet'].apply(lambda x: re.sub(pattern , '' , x ) )\n",
    "\n",
    "print(df)\n",
    "print(df.dtypes)\n",
    "df.to_csv('NVDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=75ffc756-97bb-4794-9f49-2999460b05a9 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('75ffc756-97bb-4794-9f49-2999460b05a9').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmakaCd</td>\n",
       "      <td>In actuality the #ETH/BTC ratio and value has been trending up since 2020. ://t.â€¦</td>\n",
       "      <td>2022-02-09 13:56:57+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ibrhm0172</td>\n",
       "      <td>#Bitcoin \\n\\nArkadaÅŸlar elinizde zararda olan coin varsa alÄ±ÅŸ fiyatÄ±nÄ±n ekran resmiyle birlikte bu tweet'in altÄ±na yorumâ€¦</td>\n",
       "      <td>2021-01-28 12:36:44+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moon_bore</td>\n",
       "      <td>In one week circulating supply decreased 9.3B $MCC ðŸ”¥\\n\\nWhatâ€™s next?\\n\\n-Multi Nodes with 1% daily passive income \\n-Multi printâ€¦</td>\n",
       "      <td>2021-10-07 17:40:33+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheRwopsa</td>\n",
       "      <td>Since we have invested in #Looksrare ðŸš€ \\n\\nLet's spread the word about this awesome NFT Platform that Reward their tradersâ€¦</td>\n",
       "      <td>2020-09-28 20:10:23+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ts808hw</td>\n",
       "      <td>At this rate, by the time I finish my thesis urging my superiors to consider the strategic importance of #BTC , US will hâ€¦</td>\n",
       "      <td>2017-01-05 21:21:08+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>OneCTrader</td>\n",
       "      <td>#Space</td>\n",
       "      <td>2021-02-26 07:31:33+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>jiraphamiw</td>\n",
       "      <td>ðŸ˜±ðŸ˜±</td>\n",
       "      <td>2021-08-31 14:09:30+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>mack_barnes0x</td>\n",
       "      <td>\"There are certainly a large number of coins that are commodities, including two of the biggest, which are $BTC and $ETH\"â€¦</td>\n",
       "      <td>2017-07-03 11:03:30+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>missuufe</td>\n",
       "      <td>+10,000 watchlists in \\n://t.co/BrrAV6ga6R\\n#EShib #EuroShibaInu #EuroShiba #CMC #CoinMarketCap #BSC #BNBâ€¦</td>\n",
       "      <td>2021-08-22 10:56:48+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>CaniGarcia2</td>\n",
       "      <td>Over the last year, the number of BTC transfers to exchanges has been cut by half. We expect this to accelerate in the coming yâ€¦</td>\n",
       "      <td>2019-09-16 20:38:53+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "              User                                              Tweet  \\\n",
       "0          AmakaCd      In actuality the #ETH/BTC ratio and value ...   \n",
       "1        ibrhm0172   #Bitcoin \\n\\nArkadaÅŸlar elinizde zararda olan...   \n",
       "2        moon_bore   In one week circulating supply decreased 9.3B...   \n",
       "3        TheRwopsa   Since we have invested in #Looksrare ðŸš€ \\n\\nLe...   \n",
       "4          ts808hw   At this rate, by the time I finish my thesis ...   \n",
       "..             ...                                                ...   \n",
       "995     OneCTrader                                             #Space   \n",
       "996     jiraphamiw                                                 ðŸ˜±ðŸ˜±   \n",
       "997  mack_barnes0x   \"There are certainly a large number of coins ...   \n",
       "998       missuufe   +10,000 watchlists in \\n://t.co/BrrAV6ga6R\\n#...   \n",
       "999    CaniGarcia2   Over the last year, the number of BTC transfe...   \n",
       "\n",
       "                         Time  sentiment  \n",
       "0   2022-02-09 13:56:57+00:00          3  \n",
       "1   2021-01-28 12:36:44+00:00          2  \n",
       "2   2021-10-07 17:40:33+00:00          2  \n",
       "3   2020-09-28 20:10:23+00:00          3  \n",
       "4   2017-01-05 21:21:08+00:00          2  \n",
       "..                        ...        ...  \n",
       "995 2021-02-26 07:31:33+00:00          2  \n",
       "996 2021-08-31 14:09:30+00:00          2  \n",
       "997 2017-07-03 11:03:30+00:00          3  \n",
       "998 2021-08-22 10:56:48+00:00          2  \n",
       "999 2019-09-16 20:38:53+00:00          2  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '(RT @)\\w+:'\n",
    "df['Tweet'] =df['Tweet'].apply(lambda x: re.sub(pattern , '' ,x))\n",
    "pattern = '(@)\\w+'\n",
    "df['Tweet'] =df['Tweet'].apply(lambda x: re.sub(pattern , '' ,x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "what keyword or stock symbol / crypto coin symbol would you like to analyze Saudi \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n",
      "<class 'praw.models.reddit.subreddit.Subreddit'>\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"REDDIT_SEC\"),\n",
    "    password=os.getenv(\"REDDIT_PASS\"),\n",
    "    user_agent=\"stock_dashboard by u/CryptoFoDayz\",\n",
    "    username=os.getenv(\"REDDIT_USER\"),\n",
    ")\n",
    "reddit.read_only = True\n",
    "\n",
    "keyword = input('what keyword or stock symbol / crypto coin symbol would you like to analyze')\n",
    "\n",
    "subreddit_list = []\n",
    "for subreddit in reddit.subreddits.search(keyword):\n",
    "        print(type(subreddit))\n",
    "\n",
    "\n",
    "#print(f'the following subreddits will be used for the sentiment analysis\\n {subreddit_list}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 'AAPL', 'limit': 100}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Keyword = reddit.subreddits.search('AAPL')\n",
    "\n",
    "#comments = reddit.subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = rq.get('https://cryptopanic.com/api/v1/posts/?auth_token=f2d019ca021bcf8058683396c9719215a2ae9eea&filter=rising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=19fbe9fe-575a-4689-b958-524e31ff0dc8 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('19fbe9fe-575a-4689-b958-524e31ff0dc8').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russia Just Made Bitcoin Legal!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corp. Seeks For A Crypto Business Director To Build Its Web 3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russia Moves Closer to Accepting Crypto as a Currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Salvador plans to issue first bitcoin bond next month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPMorganâ€™s Theoretical Bitcoin ($BTC) Price Target Sits at $150,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bill Introduced To Let Tennessee Buy Bitcoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Game review: Olympic Games Jam Beijing 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>McDonaldâ€™s and Panera Bread file trademarks for virtual restaurants in the metaverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>JPMorgan Says Bitcoinâ€™s Fair Value Is $38Kâ€¦ But It Still Expects BTC To Eventually Hit $150,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>JPMorgan Thinks Bitcoin Is Overvalued at $44,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                                               titles\n",
       "0                    Russia Just Made Bitcoin Legal!!\n",
       "1   Microsoft Corp. Seeks For A Crypto Business Di...\n",
       "2   Russia Moves Closer to Accepting Crypto as a C...\n",
       "3   El Salvador plans to issue first bitcoin bond ...\n",
       "4   JPMorganâ€™s Theoretical Bitcoin ($BTC) Price Ta...\n",
       "5   Russiaâ€™s Move to Regulate Cryptocurrency Puts ...\n",
       "6   BREAKING: Russia To Regulate Bitcoin As Curren...\n",
       "7   Shiba Inu Sets Course for Meme Coin Metaverse ...\n",
       "8   Gaming giant Zynga plans to launch NFT-based g...\n",
       "9   Trader Joe (JOE) makes a 110% V-shaped recover...\n",
       "10  BlackRock Planning to Offer Bitcoin Trading: R...\n",
       "11          BlackRock to Offer Crypto Trading: Report\n",
       "12  BlackRock plans to offer crypto trading servic...\n",
       "13             11 years ago today, Bitcoin reached $1\n",
       "14  Samsung Debuts on the Decentraland Ethereum Me...\n",
       "15       Bill Introduced To Let Tennessee Buy Bitcoin\n",
       "16        Game review: Olympic Games Jam Beijing 2022\n",
       "17  McDonaldâ€™s and Panera Bread file trademarks fo...\n",
       "18  JPMorgan Says Bitcoinâ€™s Fair Value Is $38Kâ€¦ Bu...\n",
       "19   JPMorgan Thinks Bitcoin Is Overvalued at $44,000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "df_json = crypto.json()\n",
    "df_json['results'][0]['title']\n",
    "\n",
    "titles = []\n",
    "for title in range(len(df_json['results'])):\n",
    "    titles.append(df_json['results'][title]['title'])\n",
    "dict_titles ={'titles':titles}\n",
    "df_titles = pd.DataFrame(dict_titles)\n",
    "df_titles\n",
    "df_titles['sentiment']=df_titles['titles'].apply(lambda x: sentiment_score(x[:]))\n",
    "df_titles.groupby(by='sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=fe6de2f4-d169-4193-96a4-e8e1b88c4896 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('fe6de2f4-d169-4193-96a4-e8e1b88c4896').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "           titles\n",
       "sentiment        \n",
       "1               1\n",
       "2              18\n",
       "3               1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titles['sentiment']=df_titles['titles'].apply(lambda x: sentiment_score(x[:]))\n",
    "df_titles.groupby(by='sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e152c43cd44c20b4f1255845dd3545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8b5b49987d484d8f7f276b5560dbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d128e26fde864850930e45844f93aacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd375cee7124c728fe5401fa0e06299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dda0a5556e44e59fb09d46c9cf8b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# create tokenizer variable to chose the model \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the list of tweet to create the sentiment score from a function\n",
    "def sentiment_score(tweet):\n",
    "    tokens = tokenizer.encode(tweet, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h4/m4qlztkx7ljd8rgkq9h9bwpr0000gn/T/ipykernel_3179/315341242.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentiment_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m990\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/h4/m4qlztkx7ljd8rgkq9h9bwpr0000gn/T/ipykernel_3179/315341242.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentiment_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m990\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/h4/m4qlztkx7ljd8rgkq9h9bwpr0000gn/T/ipykernel_3179/2819317861.py\u001b[0m in \u001b[0;36msentiment_score\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msentiment_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         )\n\u001b[1;32m   1215\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    862\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    531\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m                 )\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         )\n\u001b[1;32m    456\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2438\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "df['sentiment'] = df['Tweet'].apply(lambda x: sentiment_score(x[:990]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=892fe446-a87d-4786-ad9a-26078719afee style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('892fe446-a87d-4786-ad9a-26078719afee').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmakaCd</td>\n",
       "      <td>RT @delltronic2: @Scarcity_Mining @AmakaCd @novogratz In actuality the #ETH/BTC ratio and value has been trending up since 2020. https://t.â€¦</td>\n",
       "      <td>2022-02-09 13:56:57+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ibrhm0172</td>\n",
       "      <td>RT @hakanrecepogluu: #Bitcoin \\n\\nArkadaÅŸlar elinizde zararda olan coin varsa alÄ±ÅŸ fiyatÄ±nÄ±n ekran resmiyle birlikte bu tweet'in altÄ±na yorumâ€¦</td>\n",
       "      <td>2021-01-28 12:36:44+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moon_bore</td>\n",
       "      <td>RT @kundunsan: In one week circulating supply decreased 9.3B $MCC ðŸ”¥\\n\\nWhatâ€™s next?\\n\\n-Multi Nodes with 1% daily passive income \\n-Multi printâ€¦</td>\n",
       "      <td>2021-10-07 17:40:33+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheRwopsa</td>\n",
       "      <td>RT @LATESTDAONEWS: Since we have invested in #Looksrare ðŸš€ \\n\\nLet's spread the word about this awesome NFT Platform that Reward their tradersâ€¦</td>\n",
       "      <td>2020-09-28 20:10:23+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ts808hw</td>\n",
       "      <td>RT @JasonPLowery: At this rate, by the time I finish my thesis urging my superiors to consider the strategic importance of #BTC , US will hâ€¦</td>\n",
       "      <td>2017-01-05 21:21:08+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>OneCTrader</td>\n",
       "      <td>@BTC_Archive #Space</td>\n",
       "      <td>2021-02-26 07:31:33+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>jiraphamiw</td>\n",
       "      <td>@BTC_Archive ðŸ˜±ðŸ˜±</td>\n",
       "      <td>2021-08-31 14:09:30+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>mack_barnes0x</td>\n",
       "      <td>RT @CarpeNoctom: \"There are certainly a large number of coins that are commodities, including two of the biggest, which are $BTC and $ETH\"â€¦</td>\n",
       "      <td>2017-07-03 11:03:30+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>missuufe</td>\n",
       "      <td>RT @EShib_token: +10,000 watchlists in @CoinMarketCap\\nhttps://t.co/BrrAV6ga6R\\n#EShib #EuroShibaInu #EuroShiba #CMC #CoinMarketCap #BSC #BNBâ€¦</td>\n",
       "      <td>2021-08-22 10:56:48+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>CaniGarcia2</td>\n",
       "      <td>RT @Numbrs: Over the last year, the number of BTC transfers to exchanges has been cut by half. We expect this to accelerate in the coming yâ€¦</td>\n",
       "      <td>2019-09-16 20:38:53+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "              User                                              Tweet  \\\n",
       "0          AmakaCd  RT @delltronic2: @Scarcity_Mining @AmakaCd @no...   \n",
       "1        ibrhm0172  RT @hakanrecepogluu: #Bitcoin \\n\\nArkadaÅŸlar e...   \n",
       "2        moon_bore  RT @kundunsan: In one week circulating supply ...   \n",
       "3        TheRwopsa  RT @LATESTDAONEWS: Since we have invested in #...   \n",
       "4          ts808hw  RT @JasonPLowery: At this rate, by the time I ...   \n",
       "..             ...                                                ...   \n",
       "995     OneCTrader                                @BTC_Archive #Space   \n",
       "996     jiraphamiw                                    @BTC_Archive ðŸ˜±ðŸ˜±   \n",
       "997  mack_barnes0x  RT @CarpeNoctom: \"There are certainly a large ...   \n",
       "998       missuufe  RT @EShib_token: +10,000 watchlists in @CoinMa...   \n",
       "999    CaniGarcia2  RT @Numbrs: Over the last year, the number of ...   \n",
       "\n",
       "                         Time  sentiment  \n",
       "0   2022-02-09 13:56:57+00:00          3  \n",
       "1   2021-01-28 12:36:44+00:00          2  \n",
       "2   2021-10-07 17:40:33+00:00          2  \n",
       "3   2020-09-28 20:10:23+00:00          3  \n",
       "4   2017-01-05 21:21:08+00:00          2  \n",
       "..                        ...        ...  \n",
       "995 2021-02-26 07:31:33+00:00          2  \n",
       "996 2021-08-31 14:09:30+00:00          2  \n",
       "997 2017-07-03 11:03:30+00:00          3  \n",
       "998 2021-08-22 10:56:48+00:00          2  \n",
       "999 2019-09-16 20:38:53+00:00          2  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped= df.groupby(by ='time' , ).count()\n",
    "df_grouped.reset_index()\n",
    "df_grouped.drop(columns ='User' , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='3029'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"00eaa034-eb9f-4134-ad49-e2e19cac3634\" data-root-id=\"3029\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"332ebc9f-527f-4e6c-a680-25be79322804\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"3041\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"3077\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"tools\":[{\"id\":\"3033\"},{\"id\":\"3050\"},{\"id\":\"3051\"},{\"id\":\"3052\"},{\"id\":\"3053\"},{\"id\":\"3054\"}]},\"id\":\"3056\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"3050\",\"type\":\"SaveTool\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"black\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"top\":{\"field\":\"value\"},\"width\":{\"value\":0.8},\"x\":{\"field\":\"xoffsets\"}},\"id\":\"3072\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"3075\",\"type\":\"AllLabels\"},{\"attributes\":{\"axis\":{\"id\":\"3043\"},\"coordinates\":null,\"grid_line_color\":null,\"group\":null,\"ticker\":null},\"id\":\"3045\",\"type\":\"Grid\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer04300\",\"sizing_mode\":\"stretch_width\"},\"id\":\"3030\",\"type\":\"Spacer\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"3070\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"sentiment\",\"@{sentiment}\"],[\"Variable\",\"@{Variable}\"],[\"value\",\"@{value}\"]]},\"id\":\"3033\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"3074\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"factors\":[[\"1\",\"Time\"],[\"1\",\"Tweet\"],[\"2\",\"Time\"],[\"2\",\"Tweet\"],[\"3\",\"Time\"],[\"3\",\"Tweet\"]],\"tags\":[[[\"sentiment\",\"sentiment\",null],[\"Variable\",\"Variable\",null]]]},\"id\":\"3031\",\"type\":\"FactorRange\"},{\"attributes\":{\"source\":{\"id\":\"3064\"}},\"id\":\"3071\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"3078\",\"type\":\"AllLabels\"},{\"attributes\":{\"data\":{\"Variable\":[\"Tweet\",\"Tweet\",\"Tweet\",\"Time\",\"Time\",\"Time\"],\"sentiment\":[\"1\",\"2\",\"3\",\"1\",\"2\",\"3\"],\"value\":[42,720,238,42,720,238],\"xoffsets\":[[\"1\",\"Tweet\"],[\"2\",\"Tweet\"],[\"3\",\"Tweet\"],[\"1\",\"Time\"],[\"2\",\"Time\"],[\"3\",\"Time\"]]},\"selected\":{\"id\":\"3065\"},\"selection_policy\":{\"id\":\"3086\"}},\"id\":\"3064\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"3065\",\"type\":\"Selection\"},{\"attributes\":{\"below\":[{\"id\":\"3043\"}],\"center\":[{\"id\":\"3045\"},{\"id\":\"3049\"}],\"height\":300,\"left\":[{\"id\":\"3046\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"3070\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"3035\"},\"toolbar\":{\"id\":\"3056\"},\"width\":700,\"x_range\":{\"id\":\"3031\"},\"x_scale\":{\"id\":\"3039\"},\"y_range\":{\"id\":\"3032\"},\"y_scale\":{\"id\":\"3041\"}},\"id\":\"3034\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"hatch_alpha\":{\"value\":0.1},\"hatch_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"line_alpha\":{\"value\":0.1},\"top\":{\"field\":\"value\"},\"width\":{\"value\":0.8},\"x\":{\"field\":\"xoffsets\"}},\"id\":\"3068\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"3047\",\"type\":\"BasicTicker\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"3035\",\"type\":\"Title\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"3064\"},\"glyph\":{\"id\":\"3067\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"3069\"},\"nonselection_glyph\":{\"id\":\"3068\"},\"selection_glyph\":{\"id\":\"3072\"},\"view\":{\"id\":\"3071\"}},\"id\":\"3070\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"3051\",\"type\":\"PanTool\"},{\"attributes\":{\"end\":787.8,\"reset_end\":787.8,\"reset_start\":0.0,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"3032\",\"type\":\"Range1d\"},{\"attributes\":{\"axis_label\":\"\",\"coordinates\":null,\"formatter\":{\"id\":\"3077\"},\"group\":null,\"major_label_policy\":{\"id\":\"3078\"},\"ticker\":{\"id\":\"3047\"}},\"id\":\"3046\",\"type\":\"LinearAxis\"},{\"attributes\":{\"axis_label\":\"sentiment, Variable\",\"coordinates\":null,\"formatter\":{\"id\":\"3074\"},\"group\":null,\"major_label_policy\":{\"id\":\"3075\"},\"ticker\":{\"id\":\"3044\"}},\"id\":\"3043\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"factors\":[\"Tweet\",\"Time\"],\"palette\":[\"#30a2da\",\"#fc4f30\"]},\"id\":\"3063\",\"type\":\"CategoricalColorMapper\"},{\"attributes\":{\"bottom_units\":\"screen\",\"coordinates\":null,\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"group\":null,\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"3055\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"children\":[{\"id\":\"3030\"},{\"id\":\"3034\"},{\"id\":\"3099\"}],\"margin\":[0,0,0,0],\"name\":\"Row04296\",\"tags\":[\"embedded\"]},\"id\":\"3029\",\"type\":\"Row\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"hatch_alpha\":{\"value\":0.2},\"hatch_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"line_alpha\":{\"value\":0.2},\"top\":{\"field\":\"value\"},\"width\":{\"value\":0.8},\"x\":{\"field\":\"xoffsets\"}},\"id\":\"3069\",\"type\":\"VBar\"},{\"attributes\":{\"overlay\":{\"id\":\"3055\"}},\"id\":\"3053\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"3086\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"hatch_color\":{\"field\":\"Variable\",\"transform\":{\"id\":\"3063\"}},\"top\":{\"field\":\"value\"},\"width\":{\"value\":0.8},\"x\":{\"field\":\"xoffsets\"}},\"id\":\"3067\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"3054\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"3052\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"axis\":{\"id\":\"3046\"},\"coordinates\":null,\"dimension\":1,\"grid_line_color\":null,\"group\":null,\"ticker\":null},\"id\":\"3049\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"3044\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"3039\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer04301\",\"sizing_mode\":\"stretch_width\"},\"id\":\"3099\",\"type\":\"Spacer\"}],\"root_ids\":[\"3029\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.2\"}};\n",
       "    var render_items = [{\"docid\":\"332ebc9f-527f-4e6c-a680-25be79322804\",\"root_ids\":[\"3029\"],\"roots\":{\"3029\":\"00eaa034-eb9f-4134-ad49-e2e19cac3634\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined && ( root['Plotly'] !== undefined)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined && (root['Plotly'] !== undefined)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":Bars   [sentiment,Variable]   (value)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "3029"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.hvplot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=5a243c66-3e91-4d80-a2c0-7f7f06dc044c style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('5a243c66-3e91-4d80-a2c0-7f7f06dc044c').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "           Tweet  Time\n",
       "sentiment             \n",
       "1             42    42\n",
       "2            720   720\n",
       "3            238   238"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70258ac2307775ea3b2356ae640b2cec78ea29d8e88ec85f576a7eb81644faaf"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
